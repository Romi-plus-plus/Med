# Med
"Med"是耳动检测交互系统的工程名，包含Medtalk和Medect两个部分。Med是“move ear detection”的首字母组合，也是制作人对这项工程可以成为交互技术一剂良药的期盼。   
Med_talk是耳动设备配套的用户问答系统，采用典型前后端分离架构，共包含五层结构：应用层、用户界面层、接口层、业务逻辑层、数据层。本项目采用典型前后端分离架构。业务层围绕用户回答展开，包含会话记录、回答反馈、用户信息和会话信息管理、个性化、后台管理和知识库管理；问答的生成基于Joint-bert模型识别，通过寻找后台数据库来给出准确的官方答案。问答内容包罗万象，从设备出现的软硬件问题、关于设备的种种疑问、不适应症状以及对应处理方法到对于整个设备的设计理念，设备各项指标。用户不满意可以反馈回答或者发起投诉进程，管理员可以后台看见并处理。管理员也可以对用户采取分类、打标签、禁言等操作。    
架构具体而言，前端使用基于 Vite 构建的 Vue 实现动态网站，后端运行于 Uvicorn 的 WSGI 异步服务器，基于 FastAPI 实现接口请求处理。数据访问方面，以 SQLModel 为核心，它融合了经典的 SQLAlchemy 和 Pydantic，描述了数据表和关系数据库实体，一模型两用，可以直接将数据库查询和输入输出做映射。FastAPI 与 Pydantic 结合很好地实现了前后端输出校验和异常处理。前端通过 Axios 发送 http 请求，增加自定义拦截器处理异常，数据库采用堪称最佳的 PostgreSQL，借助 SQLModel 实现增删改查。在此基础上，后端形成了 4 层模型。首先是路由层（router），直接处理前端请求。然后调用服务层（service）完成响应的业务逻辑。它又依赖了数据访问层（CRUD，增删改查），通过声明式语句模拟 SQL 对数据库进行直接操作。最后是数据模型层，和数据库实体一一对应。服务层的模块可以在其他入口模块，如初始数据构建，进行调用。功能逻辑逐层细化。   
Medtalk还使用到 AI 模型实现问答，将其作为微服务独立部署。其采取类似的后端架构，拥有路由层、服务层，但是数据库使用的是 neo4j，未用到 ORM 技术，且涉及的功能较少，仅有简单的查询，故在服务层下直接设了数据访问层。AI 模型包括识别意图和提问实体的 JointBert、命名实体识别的 Jieba（主要用于大数据统计），均作为独立模块的子微服务。以 pipeline 的形式实现服务层，依次进行问句分析、图搜索、回答生成。后端（主）与 AI 服务采用异步 http 通信，实现了三部分可独立开发、独立运行。前端使用的 Vue TypeScript 和后端使用的FastAPI + SQLModel 均提供了优秀的类型注解，为开发调试提供了极大的方便。而 FastAPI 自带动态生成的接口文档，可以直接模拟前端和后端交互。  
Medect是交互设备识别的算法核心的一部分代码原型，包含调节摄像头，角点检测，LK光流法和初步拟合，仅作为参考。完整算法在专利保密期内，细节不方便透露。核心是通过对不同动作产生的耳朵震动的图像变化的识别，从而控制获得规定的输出信号。同时也给出了基于unity的交互识别场景案例demo，带上VR眼镜可以自行尝试。
